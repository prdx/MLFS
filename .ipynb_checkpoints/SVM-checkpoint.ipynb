{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Anak Agung Ngurah Bagus Trihatmaja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helper.py\n",
    "from sklearn import svm\n",
    "# General functions for this problem\n",
    "# Kernel\n",
    "def linear_kernel(x, y):\n",
    "  return np.dot(x, y.T)\n",
    "\n",
    "def classification_error(x, y, weight, intercept):\n",
    "    count = 0\n",
    "    for i in range(0, len(y)):\n",
    "        predicted = np.dot(x[i], weight.T) + intercept\n",
    "        if predicted > 0:\n",
    "            \n",
    "            if y[i] < 0:\n",
    "                count += 1\n",
    "        else:\n",
    "            if y[i] > 0:\n",
    "                count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement SVM with the SMO algorithm and train it on the provided dataset. For\n",
    "your implementation,\n",
    "you only have to use the linear kernel. In addition, run\n",
    "SVM using sklearn in python and\n",
    "compare the results. You can implement the\n",
    "simplified SMO, as described in\n",
    "http://cs229.stanford.edu/materials/smo.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Simplified SMO\n",
    "Input:\n",
    "  C: regularization parameter\n",
    "  tol: numerical tolerance\n",
    "  max_passes: max # of times to iterate over α’s without changing\n",
    "  training_data: training data\n",
    "\n",
    "Output:\n",
    "  alpha: Lagrange multipliers for solution (vector)\n",
    "  b: threshold for solution\n",
    "\n",
    "'''\n",
    "def formula_2(X, y, b, alpha, x):\n",
    "    res = 0\n",
    "    # print(x)\n",
    "    for i in range(0, len(y)):\n",
    "        res += (alpha[i] * y[i] * linear_kernel(X[i], x))\n",
    "    res += b\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def clip_alpha(alpha, L, H):\n",
    "    if alpha > H:\n",
    "        alpha = H\n",
    "    elif alpha < L:\n",
    "        alpha = L\n",
    "    return alpha\n",
    "\n",
    "def simplified_smo(C, tol, max_passes, X, y):\n",
    "    # Initialize αi = 0, ∀i, b = 0.\n",
    "    alpha = np.zeros(y.shape[0])\n",
    "    \n",
    "    b = 0\n",
    "    # Initialize passes = 0.\n",
    "    passes = 0\n",
    "\n",
    "    # Initialize E\n",
    "    E = np.zeros(y.shape[0])\n",
    "    # print(len(y))\n",
    "\n",
    "    while passes < max_passes:\n",
    "        num_changed_alphas = 0\n",
    "        for i in range(0, len(y)):\n",
    "            # Calculate Ei = f(x(i)) − y(i) using (2)\n",
    "            E[i] = formula_2(X, y, b, alpha, X[i]) - float(y[i])\n",
    "\n",
    "            if (y[i] * E[i] < -tol and alpha[i] < C) or (y[i] * E[i] > -tol and alpha[i] > 0):\n",
    "                # Select j != i randomly\n",
    "                j = i\n",
    "                while j == i:\n",
    "                    j = np.random.randint(1, y.size-1)\n",
    "                # print(j)\n",
    "\n",
    "                E[j] = formula_2(X, y, b, alpha, X[j]) - float(y[j])\n",
    "                alpha_old_i = alpha[i].copy()\n",
    "                alpha_old_j = alpha[j].copy()\n",
    "\n",
    "                # Compute L and H by (10) or (11)\n",
    "                # L is lower bound\n",
    "                # H is higher bound \n",
    "                if y[i] != y[j]:\n",
    "                    # If y(i) 6= y(j), L = max(0, αj − αi), \n",
    "                    # H = min(C, C + αj − αi)\n",
    "                    L = max(0, alpha[j] - alpha[i])\n",
    "                    H = min(C, C + alpha[j] - alpha[i])\n",
    "                else:\n",
    "                    # If y(i) = y(j), L = max(0, αi + αj − C),\n",
    "                    # H = min(C, αi + αj)\n",
    "                    L = max(0, alpha[i] + alpha[j] - C)\n",
    "                    H = min(C, alpha[i] + alpha[j])\n",
    "                    # print(alpha[i] + alpha[j] - C)\n",
    "                    # print(alpha[i] + alpha[j])\n",
    "                                 \n",
    "\n",
    "                if L == H:\n",
    "                    continue\n",
    "\n",
    "                eta = 2.0 * linear_kernel(X[i], X[j]) - linear_kernel(X[i], X[i]) - linear_kernel(X[j], X[j])\n",
    "                if eta >= 0:\n",
    "                    continue\n",
    "\n",
    "                alpha[j] = alpha[j] - y[j] * (E[i] - E[j]) / eta\n",
    "                alpha[j] = clip_alpha(alpha[j], L, H)\n",
    "                                \n",
    "                if abs(alpha[j] - alpha_old_j) < 1e-5:\n",
    "                    continue\n",
    "                    \n",
    "                # Determine value for αi using (16)\n",
    "                # αi:= αi + y(i)y(j)(α(old)j − αj)\n",
    "                alpha[i] += y[i] * y[j] * (alpha_old_j - alpha[j])\n",
    "                \n",
    "                # Compute b1 and b2 using (17) and (18) respectively\n",
    "                # b1 = b − Ei − y(i)(αi − α(old)i)<x(i), x(i)> − y(j)(αj − α(old)j)<x(i), x(j)>\n",
    "                # b1 = b - E[i] - y[i]*(alpha[i] - alphas_old[i])*np.dot(X[i], X[i].T) - y[j]*(alpha[j] - alphas_old_j)*np.dot(X[i], X[j].T)\n",
    "                # b2 = b - E[j] - y[i]*(alpha[i] - alphas_old[i])*np.dot(X[i], X[j].T) - y[j]*(alpha[j] - alphas_old_j)*np.dot(X[j], X[j].T)\n",
    "                \n",
    "                b1 = b - E[i] - y[i] * \\\n",
    "                (alpha[i] - alpha_old_i) * linear_kernel(X[i], X[i]) - \\\n",
    "                y[j] * (alpha[j] - alpha_old_j) * linear_kernel(X[i], X[j])\n",
    "                \n",
    "                # b2 = b − Ei − y(i)(αi − α(old)i)<x(i), x(j)> − y(j)(αj − α(old)j)<x(j), x(j)>\n",
    "                b2 = b - E[j] - y[i] * \\\n",
    "                (alpha[i] - alpha_old_i) * linear_kernel(X[i], X[j]) - \\\n",
    "                y[j] * (alpha[j] - alpha_old_j) * linear_kernel(X[j], X[j])\n",
    "                \n",
    "                if alpha[i] > 0 and alpha[i] < C:\n",
    "                    b = b1\n",
    "                elif alpha[j] > 0 and alpha[j] < C:\n",
    "                    b = b2\n",
    "                else:\n",
    "                    b = (b1 + b2) / 2.0\n",
    "                \n",
    "                num_changed_alphas += 1\n",
    "        \n",
    "        if num_changed_alphas == 0:\n",
    "            passes += 1\n",
    "        else:\n",
    "            passes = 0\n",
    "                \n",
    "\n",
    "    return alpha, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A\n",
    "\n",
    "Apply the SVM on the ‘dataset1’ and report the classification error (on\n",
    "both training and test\n",
    "sets) as a function of the regularization parameter C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset 1\n",
    "ds1 = scipy.io.loadmat('data1.mat')\n",
    "ds1_train_X = ds1['X_trn']\n",
    "ds1_test_X = ds1['X_tst']\n",
    "ds1_train_Y = ds1['Y_trn']\n",
    "ds1_test_Y = ds1['Y_tst']\n",
    "\n",
    "ds1_train_Y = ds1_train_Y.astype(float)\n",
    "ds1_train_X = ds1_train_X.astype(float)\n",
    "\n",
    "for n, i in enumerate(ds1_train_Y):\n",
    "    if i == 0:\n",
    "        ds1_train_Y[n][0] = ds1_train_Y[n][0] - 1 \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res = simplified_smo(100, 0.001, 70, ds1_train_X, ds1_train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w = np.zeros((1, ds1_train_X.shape[1]))\n",
    "\n",
    "for i in range(ds1_train_Y.size):\n",
    "    w += res[0][i] * ds1_train_Y[i] * ds1_train_X[i]\n",
    "\n",
    "\n",
    "print(\"(Simplified SMO) coefficient:\") \n",
    "print(w)\n",
    "print(\"(Simplified SMO) intercept:\") \n",
    "print(res[1])\n",
    "print(\"(Simplified SMO) Error from the training set is:\")\n",
    "print(classification_error(ds1_train_X, ds1_train_Y, w_opt, res[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(C=100, kernel='linear', tol=0.001)\n",
    "clf.fit(ds1_train_X, ds1_train_Y)\n",
    "\n",
    "print(\"(Sklearn) coefficient:\") \n",
    "print(clf.coef_)\n",
    "print(\"(Sklearn) intercept:\") \n",
    "print(clf.intercept_)\n",
    "print(\"(Sklearn) Error from the training set is:\")\n",
    "print(classification_error(ds1_train_X, ds1_train_Y, clf.coef_, clf.intercept_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(clf.coef_)\n",
    "print(clf.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"(Simplified SMO) Error from the training set is:\")\n",
    "print(classification_error(ds1_test_X, ds1_test_Y, w_opt, res[1]))\n",
    "\n",
    "print(\"(Sklearn) Error from the training set is:\")\n",
    "print(classification_error(ds1_test_X, ds1_test_Y, clf.coef_, clf.intercept_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B\n",
    "\n",
    "Repeat part A using ‘dataset2’. Explain the differences in results\n",
    "between part A and B and\n",
    "justify your observations/results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset 1\n",
    "ds2 = scipy.io.loadmat('data2.mat')\n",
    "ds2_train_X = ds2['X_trn']\n",
    "ds2_test_X = ds2['X_tst']\n",
    "ds2_train_Y = ds2['Y_trn']\n",
    "ds2_test_Y = ds2['Y_tst']\n",
    "\n",
    "ds2_train_Y = ds2_train_Y.astype(float)\n",
    "ds2_train_X = ds2_train_X.astype(float)\n",
    "\n",
    "for n, i in enumerate(ds2_train_Y):\n",
    "    if i == 0:\n",
    "        ds2_train_Y[n][0] = ds2_train_Y[n][0] - 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = simplified_smo(100, 0.001, 70, ds2_train_X, ds2_train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.zeros((1, ds2_train_X.shape[1]))\n",
    "\n",
    "for i in range(ds2_train_Y.size):\n",
    "    w += res[0][i] * ds2_train_Y[i] * ds2_train_X[i]\n",
    "\n",
    "\n",
    "print(\"(Simplified SMO) coefficient:\") \n",
    "print(w)\n",
    "print(\"(Simplified SMO) intercept:\") \n",
    "print(res[1])\n",
    "print(\"(Simplified SMO) Error from the training set is:\")\n",
    "print(classification_error(ds2_train_X, ds2_train_Y, w_opt, res[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(C=100, kernel='linear', tol=0.001)\n",
    "clf.fit(ds2_train_X, ds2_train_Y)\n",
    "\n",
    "print(\"(Sklearn) coefficient:\") \n",
    "print(clf.coef_)\n",
    "print(\"(Sklearn) intercept:\") \n",
    "print(clf.intercept_)\n",
    "print(\"(Sklearn) Error from the training set is:\")\n",
    "print(classification_error(ds2_train_X, ds2_train_Y, clf.coef_, clf.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"(Simplified SMO) Error from the training set is:\")\n",
    "print(classification_error(ds2_test_X, ds2_test_Y, w_opt, res[1]))\n",
    "\n",
    "print(\"(Sklearn) Error from the training set is:\")\n",
    "print(classification_error(ds2_test_X, ds2_test_Y, clf.coef_, clf.intercept_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both sklearn and our simplified SMO result the same. It has errors on the training dataset for dataset2, because it is non-linearly separable. Here we are using linear kernel. Changing the kernel should result have better result.\n",
    "\n",
    "In this assignment, I have also tried if `C` and the `tol` have influence in our result. Apparently they have no influence and we still have the same error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
